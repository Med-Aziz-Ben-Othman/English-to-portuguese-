{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2iMBP3_RXVB"
      },
      "source": [
        "# ***Necessary Importations***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5PEBMDiSoGXR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from string import digits\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GRU, Embedding,Dropout,LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U8DcincPD8l"
      },
      "source": [
        "# ***Loading data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "krJpJKzwdfe5"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"por.txt\", \n",
        "                      sep='\\t', \n",
        "                 \n",
        "                      names=[\"EN\",\"PT\", \"Attribution\"], \n",
        "                      header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dzBoUBdNQu8w"
      },
      "outputs": [],
      "source": [
        "df = data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z5VWTKmKQ7ak",
        "outputId": "fb93711e-85a1-4117-a0cb-3c5d6bdac8a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d62496be-8a62-4aa7-bbaf-be5ae3ac49c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EN</th>\n",
              "      <th>PT</th>\n",
              "      <th>Attribution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you think of those Japanese writers?</td>\n",
              "      <td>O que você acha desses escritores japoneses?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom hasn't finished his homework yet.</td>\n",
              "      <td>Tom ainda não terminou o dever de casa.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I like you as a friend.</td>\n",
              "      <td>Eu gosto de você como amigo.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I know that guy. His name's Tom.</td>\n",
              "      <td>Eu conheço esse cara. O nome dele é Tom.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He wants one.</td>\n",
              "      <td>Ele quer um.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d62496be-8a62-4aa7-bbaf-be5ae3ac49c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d62496be-8a62-4aa7-bbaf-be5ae3ac49c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d62496be-8a62-4aa7-bbaf-be5ae3ac49c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             EN  \\\n",
              "0  What do you think of those Japanese writers?   \n",
              "1         Tom hasn't finished his homework yet.   \n",
              "2                       I like you as a friend.   \n",
              "3              I know that guy. His name's Tom.   \n",
              "4                                 He wants one.   \n",
              "\n",
              "                                             PT  \\\n",
              "0  O que você acha desses escritores japoneses?   \n",
              "1       Tom ainda não terminou o dever de casa.   \n",
              "2                  Eu gosto de você como amigo.   \n",
              "3      Eu conheço esse cara. O nome dele é Tom.   \n",
              "4                                  Ele quer um.   \n",
              "\n",
              "                                         Attribution  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Ky0YUZrEC9U"
      },
      "outputs": [],
      "source": [
        "#precise the english sentences and the portuguese senetences \n",
        "english_sentences=df['EN']\n",
        "portuguese_sentences=df['PT']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H7eRX2NzCcJM"
      },
      "outputs": [],
      "source": [
        "#add letter s=start as a starting token and e=end as an ending token\n",
        "portuguese_sentences=\"s \"+portuguese_sentences+\" e\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p1bKnbOArJ9x"
      },
      "outputs": [],
      "source": [
        "mark_start = 's '\n",
        "mark_end = 'e'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32CBqxwHPeqU"
      },
      "source": [
        "# ***Preprocessing phase***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXQ5zqK8yJls"
      },
      "outputs": [],
      "source": [
        "# Lowercase all characters\n",
        "english_sentences=english_sentences.apply(lambda x: x.lower())\n",
        "portuguese_sentences=portuguese_sentences.apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vuJlJ32yJoP"
      },
      "outputs": [],
      "source": [
        "# Remove quotes\n",
        "english_sentences=english_sentences.apply(lambda x:  re.sub(\"'\", '', x))\n",
        "portuguese_sentences=portuguese_sentences.apply(lambda x:  re.sub(\"'\", '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMTY-Uz6yJq-"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "english_sentences=english_sentences.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "portuguese_sentencesi=portuguese_sentences.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV3U6B0syJtm"
      },
      "outputs": [],
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "english_sentences=english_sentences.apply(lambda x: x.translate(remove_digits))\n",
        "portuguese_sentences=portuguese_sentences.apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "portuguese_sentences = portuguese_sentences.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "english_sentences=english_sentences.apply(lambda x: x.strip())\n",
        "portuguese_sentences=portuguese_sentences.apply(lambda x: x.strip())\n",
        "english_sentences=english_sentences.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "portuguese_sentences=portuguese_sentences.apply(lambda x: re.sub(\" +\", \" \", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ia4ZBRARqcES"
      },
      "outputs": [],
      "source": [
        "num_words = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create A class called TokenizerWrap in which you create methods to use in predictions phase and also we will use this class for the word embedding techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b70jP_E5qcBZ"
      },
      "outputs": [],
      "source": [
        "class TokenizerWrap(Tokenizer):\n",
        "    \n",
        "    def __init__(self, texts, padding,\n",
        "                 reverse=False, num_words=None):\n",
        "\n",
        "        Tokenizer.__init__(self, num_words=num_words)\n",
        "\n",
        "        # Create the vocabulary from the texts.\n",
        "        self.fit_on_texts(texts)\n",
        "\n",
        "        # Create inverse lookup from integer-tokens to words.\n",
        "        self.index_to_word = dict(zip(self.word_index.values(),\n",
        "                                      self.word_index.keys()))\n",
        "\n",
        "        # Convert all texts to lists of integer-tokens.\n",
        "        # Note that the sequences may have different lengths.\n",
        "        self.tokens = self.texts_to_sequences(texts)\n",
        "\n",
        "        if reverse:\n",
        "            # Reverse the token-sequences.\n",
        "            self.tokens = [list(reversed(x)) for x in self.tokens]\n",
        "        \n",
        "            # Sequences that are too long should now be truncated\n",
        "            # at the beginning, which corresponds to the end of\n",
        "            # the original sequences.\n",
        "            truncating = 'pre'\n",
        "        else:\n",
        "            # Sequences that are too long should be truncated\n",
        "            # at the end.\n",
        "            truncating = 'post'\n",
        "\n",
        "        # The number of integer-tokens in each sequence.\n",
        "        self.num_tokens = [len(x) for x in self.tokens]\n",
        "\n",
        "        # Max number of tokens to use in all sequences.\n",
        "        # We will pad / truncate all sequences to this length.\n",
        "        # This is a compromise so we save a lot of memory and\n",
        "        # only have to truncate maybe 5% of all the sequences.\n",
        "        self.max_tokens = np.mean(self.num_tokens) \\\n",
        "                          + 2 * np.std(self.num_tokens)\n",
        "        self.max_tokens = int(self.max_tokens)\n",
        "\n",
        "        # Pad / truncate all token-sequences to the given length.\n",
        "        # This creates a 2-dim numpy matrix that is easier to use.\n",
        "        self.tokens_padded = pad_sequences(self.tokens,\n",
        "                                           maxlen=self.max_tokens,\n",
        "                                           padding=padding,\n",
        "                                           truncating=truncating)\n",
        "\n",
        "    def token_to_word(self, token):\n",
        "\n",
        "        word = \" \" if token == 0 else self.index_to_word[token]\n",
        "        return word \n",
        "\n",
        "    def tokens_to_string(self, tokens):\n",
        "\n",
        "\n",
        "        # Create a list of the individual words.\n",
        "        words = [self.index_to_word[token]\n",
        "                 for token in tokens\n",
        "                 if token != 0]\n",
        "        \n",
        "        # Concatenate the words to a single string\n",
        "        # with space between all the words.\n",
        "        text = \" \".join(words)\n",
        "\n",
        "        return text\n",
        "    \n",
        "    def text_to_tokens(self, text, reverse=False, padding=False):\n",
        "        # Convert to tokens. Note that we assume there is only\n",
        "        # a single text-string so we wrap it in a list.\n",
        "        tokens = self.texts_to_sequences([text])\n",
        "        tokens = np.array(tokens)\n",
        "\n",
        "        if reverse:\n",
        "            # Reverse the tokens.\n",
        "            tokens = np.flip(tokens, axis=1)\n",
        "\n",
        "            # Sequences that are too long should now be truncated\n",
        "            # at the beginning, which corresponds to the end of\n",
        "            # the original sequences.\n",
        "            truncating = 'pre'\n",
        "        else:\n",
        "            # Sequences that are too long should be truncated\n",
        "            # at the end.\n",
        "            truncating = 'post'\n",
        "\n",
        "        if padding:\n",
        "            # Pad and truncate sequences to the given length.\n",
        "            tokens = pad_sequences(tokens,\n",
        "                                   maxlen=self.max_tokens,\n",
        "                                   padding='pre',\n",
        "                                   truncating=truncating)\n",
        "\n",
        "        return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oDWCQvMQEUU"
      },
      "source": [
        "# ***Word Embedding adn data splitting***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UHYroLq4qb-o"
      },
      "outputs": [],
      "source": [
        "tokenizer_src = TokenizerWrap(texts=english_sentences,\n",
        "                              padding='pre',\n",
        "                              reverse=True,\n",
        "                              num_words=num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-C-mowm1qb75"
      },
      "outputs": [],
      "source": [
        "tokenizer_dest = TokenizerWrap(texts=portuguese_sentences,\n",
        "                               padding='post',\n",
        "                               reverse=False,\n",
        "                               num_words=num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBvU1bwcqb5R",
        "outputId": "89f2f703-eaf4-4f3e-f62d-00f489c171f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(168903, 10)\n",
            "(168903, 12)\n"
          ]
        }
      ],
      "source": [
        "tokens_src = tokenizer_src.tokens_padded\n",
        "tokens_dest = tokenizer_dest.tokens_padded\n",
        "print(tokens_src.shape)\n",
        "print(tokens_dest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DujtVCq4qzlb",
        "outputId": "58d4f5e4-c048-461e-8481-e07a3ba6e2a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_start = tokenizer_dest.word_index[mark_start.strip()]\n",
        "token_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxYi5xmtqzip",
        "outputId": "c2f1e34e-53d4-4440-ec2f-ecaa63c70e2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_end = tokenizer_dest.word_index[mark_end.strip()]\n",
        "token_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "km5A9reCqzgB"
      },
      "outputs": [],
      "source": [
        "encoder_input_data = tokens_src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIw153_Aqzb5",
        "outputId": "ee5edfc8-aa7e-4887-eb0d-ed5ad7995bdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(168903, 11)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input_data = tokens_dest[:, :-1]\n",
        "decoder_input_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_B2PwRmrdYp",
        "outputId": "aa77beba-e871-4857-9cff-e993c4eec07b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(168903, 11)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_output_data = tokens_dest[:, 1:]\n",
        "decoder_output_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjIJ3OubQP0t"
      },
      "source": [
        "# ***Model Creattion***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nYCkkcHRqPTL"
      },
      "outputs": [],
      "source": [
        "encoder_input = Input(shape=(None, ), name='encoder_input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jY605OTvqigH"
      },
      "outputs": [],
      "source": [
        "embedding_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UknqoV4KqidD"
      },
      "outputs": [],
      "source": [
        "encoder_embedding = Embedding(input_dim=num_words,\n",
        "                              output_dim=embedding_size,\n",
        "                              name='encoder_embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pbH9xod2qucw"
      },
      "outputs": [],
      "source": [
        "state_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KcM1dAaMqsgZ"
      },
      "outputs": [],
      "source": [
        "encoder_gru1 = GRU(state_size, name='encoder_gru1', return_sequences=True)\n",
        "dropout_encoder1=Dropout(0.2, name='dropout_encoder1')\n",
        "\n",
        "encoder_gru2 = GRU(state_size, name='encoder_gru2', return_sequences=True)\n",
        "dropout_encoder2=Dropout(0.2, name='dropout_encoder2')\n",
        "\n",
        "encoder_gru3 = GRU(state_size, name='encoder_gru3',return_sequences=False)                  \n",
        "dropout_encoder3=Dropout(0.2, name='dropout_encoder3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Fim0blUNqiak"
      },
      "outputs": [],
      "source": [
        "def connect_encoder():\n",
        "    # Start the neural network with its input-layer.\n",
        "    net = encoder_input\n",
        "    \n",
        "    # Connect the embedding-layer.\n",
        "    net = encoder_embedding(net)\n",
        "\n",
        "    # Connect all the GRU-layers.\n",
        "    net = encoder_gru1(net)\n",
        "    net = dropout_encoder1(net)\n",
        "    net = encoder_gru2(net)\n",
        "    net = dropout_encoder2(net)\n",
        "    net = encoder_gru3(net)\n",
        "    net = dropout_encoder3(net)\n",
        "\n",
        "    # This is the output of the encoder.\n",
        "    encoder_output = net\n",
        "    \n",
        "    return encoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jNZ7qvZ4qzGi"
      },
      "outputs": [],
      "source": [
        "encoder_output = connect_encoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NZFqowwkqzJn"
      },
      "outputs": [],
      "source": [
        "decoder_initial_state = Input(shape=(state_size,),name='decoder_initial_state')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "inMr7vbSqzSI"
      },
      "outputs": [],
      "source": [
        "decoder_input = Input(shape=(None, ), name='decoder_input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b_sbGlL3qiYD"
      },
      "outputs": [],
      "source": [
        "decoder_embedding = Embedding(input_dim=num_words,\n",
        "                              output_dim=embedding_size,\n",
        "                              name='decoder_embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V6ptMh0MrJxm"
      },
      "outputs": [],
      "source": [
        "decoder_gru1 = GRU(state_size, name='decoder_gru1',  return_sequences=True)                 \n",
        "dropout_decoder1=Dropout(0.2, name='dropout_decoder1')\n",
        "\n",
        "decoder_gru2 = GRU(state_size, name='decoder_gru2',return_sequences=True)\n",
        "dropout_decoder2=Dropout(0.2, name='dropout_decoder2')\n",
        "\n",
        "decoder_gru3 = GRU(state_size, name='decoder_gru3',return_sequences=True)\n",
        "dropout_decoder3=Dropout(0.2, name='dropout_decoder3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6vXyULbprJ0h"
      },
      "outputs": [],
      "source": [
        "decoder_dense = Dense(num_words,\n",
        "                      activation='softmax',\n",
        "                      name='decoder_output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EiRLhTC7rJ3Q"
      },
      "outputs": [],
      "source": [
        "def connect_decoder(initial_state):\n",
        "    # Start the decoder-network with its input-layer.\n",
        "    net = decoder_input\n",
        "\n",
        "    # Connect the embedding-layer.\n",
        "    net = decoder_embedding(net)\n",
        "    \n",
        "    # Connect all the GRU-layers.\n",
        "    net = decoder_gru1(net, initial_state=initial_state)\n",
        "    net = dropout_decoder1(net)\n",
        "    net = decoder_gru2(net, initial_state=initial_state)\n",
        "    net = dropout_decoder2(net )\n",
        "    net = decoder_gru3(net, initial_state=initial_state)\n",
        "    net = dropout_decoder3(net )\n",
        "\n",
        "    # Connect the final dense layer that converts to\n",
        "    # one-hot encoded arrays.\n",
        "    decoder_output = decoder_dense(net)\n",
        "    \n",
        "    return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E1Z3hrgTm12U"
      },
      "outputs": [],
      "source": [
        "decoder_output = connect_decoder(initial_state=encoder_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qc5XhzrxrR-i"
      },
      "outputs": [],
      "source": [
        "model_train = Model(inputs=[encoder_input, decoder_input],\n",
        "                    outputs=[decoder_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TQ13JRElrSBW"
      },
      "outputs": [],
      "source": [
        "model_encoder = Model(inputs=[encoder_input],\n",
        "                      outputs=[encoder_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VESOKM_lrSEf"
      },
      "outputs": [],
      "source": [
        "decoder_output = connect_decoder(initial_state=decoder_initial_state)\n",
        "\n",
        "model_decoder = Model(inputs=[decoder_input, decoder_initial_state],\n",
        "                      outputs=[decoder_output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReqUpKmaQVmt"
      },
      "source": [
        "# ***Compiling the model and makie data in dicts***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvI8FbtUrSHD",
        "outputId": "9cfba3a8-ba01-479a-ff23-d9269514573d"
      },
      "outputs": [],
      "source": [
        "model_train.compile(optimizer=RMSprop(lr=1e-3),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MEK6DxeCrJ6Z"
      },
      "outputs": [],
      "source": [
        "x_data = \\\n",
        "{\n",
        "    'encoder_input': encoder_input_data,\n",
        "    'decoder_input': decoder_input_data\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7kaKAvowryi_"
      },
      "outputs": [],
      "source": [
        "y_data = \\\n",
        "{\n",
        "    'decoder_output': decoder_output_data\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FACQ6bVSrylo",
        "outputId": "9fa25ad5-31f2-4ffc-8af8-256f87364029"
      },
      "outputs": [],
      "source": [
        "validation_split = 10000 / len(encoder_input_data)\n",
        "validation_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z64XD8UQeFd"
      },
      "source": [
        "# ***Fit the model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfGbIM3Sryn8"
      },
      "outputs": [],
      "source": [
        "print(model_train.summary())\n",
        "model_train.fit(x=x_data,\n",
        "                y=y_data,\n",
        "                batch_size=384,\n",
        "                epochs=150,\n",
        "                validation_split=validation_split,\n",
        "                )\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws0iLhfBQied"
      },
      "source": [
        "# ***Make Predictions***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VzZx-5-HrdQ6"
      },
      "outputs": [],
      "source": [
        "def translate(input_text, true_output_text=None):\n",
        "\n",
        "    # Convert the input-text to integer-tokens.\n",
        "    input_tokens = tokenizer_src.text_to_tokens(text=input_text,\n",
        "                                                reverse=True,\n",
        "                                                padding=True)\n",
        "    \n",
        "    # Get the output of the encoder's GRU which will be used as the initial state in the decoder's GRU.\n",
        "    initial_state = model_encoder.predict(input_tokens)\n",
        "\n",
        "    # Max number of tokens / words in the output sequence.\n",
        "    max_tokens = tokenizer_dest.max_tokens\n",
        "\n",
        "    # Pre-allocate the 2-dim array used as input to the decoder.\n",
        "    # This holds just a single sequence of integer-tokens,\n",
        "    # but the decoder-model expects a batch of sequences.\n",
        "    shape = (1, max_tokens)\n",
        "    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n",
        "\n",
        "    # The first input-token is the special start-token for 's '.\n",
        "    token_int = token_start\n",
        "\n",
        "    # Initialize an empty output-text.\n",
        "    output_text = ''\n",
        "\n",
        "    # Initialize the number of tokens we have processed.\n",
        "    count_tokens = 0\n",
        "\n",
        "    # While we haven't sampled the special end-token for ' e'\n",
        "    # and we haven't processed the max number of tokens.\n",
        "    while token_int != token_end and count_tokens < max_tokens:\n",
        "        # Update the input-sequence to the decoder\n",
        "        # with the last token that was sampled.\n",
        "        # In the first iteration this will set the\n",
        "        # first element to the start-token.\n",
        "        decoder_input_data[0, count_tokens] = token_int\n",
        "\n",
        "        # Wrap the input-data in a dict for clarity and safety,\n",
        "        x_data = \\\n",
        "        {\n",
        "            'decoder_initial_state': initial_state,\n",
        "            'decoder_input': decoder_input_data\n",
        "        }\n",
        "\n",
        "        # Input this data to the decoder and get the predicted output.\n",
        "        decoder_output = model_decoder.predict(x_data)\n",
        "\n",
        "        # Get the last predicted token as a one-hot encoded array.\n",
        "        token_onehot = decoder_output[0, count_tokens, :]\n",
        "        \n",
        "        # Convert to an integer-token.\n",
        "        token_int = np.argmax(token_onehot)\n",
        "\n",
        "        # Lookup the word corresponding to this integer-token.\n",
        "        sampled_word = tokenizer_dest.token_to_word(token_int)\n",
        "\n",
        "        # Append the word to the output-text.\n",
        "        output_text += \" \" + sampled_word\n",
        "\n",
        "        # Increment the token-counter.\n",
        "        count_tokens += 1\n",
        "\n",
        "    # Sequence of tokens output by the decoder.\n",
        "    output_tokens = decoder_input_data[0]\n",
        "    \n",
        "    # Print the input-text.\n",
        "    print(\"Input text:\")\n",
        "    print(input_text)\n",
        "    print()\n",
        "\n",
        "    # Print the translated output-text.\n",
        "    print(\"Translated text:\")\n",
        "    print(output_text)\n",
        "    print()\n",
        "\n",
        "    # Optionally print the true translated text.\n",
        "    if true_output_text is not None:\n",
        "        print(\"True output text:\")\n",
        "        print(true_output_text)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH5pnFkardOC",
        "outputId": "ca262847-2108-4669-8a8f-eedac02beed4"
      },
      "outputs": [],
      "source": [
        "#make predictions on the \n",
        "idx=9988\n",
        "translate(input_text=english_sentences[idx],\n",
        "          true_output_text=portuguese_sentences[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf17opKpBxwp",
        "outputId": "70b031e7-7c95-4d8d-94f8-90370845aa86"
      },
      "outputs": [],
      "source": [
        "translate(input_text='I know how to do it',\n",
        "          true_output_text=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HOvS3XLxrdLJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "machine_translation1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
